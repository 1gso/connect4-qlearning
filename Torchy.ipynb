{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e76b0-805e-4663-90e9-a217e05f9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and device check\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check PyTorch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c15a7-2cc2-476d-88fc-87ba8a7a516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load features + Monte Carlo Q-values from .h5\n",
    "\n",
    "h5_path = r\"D:\\SFTP\\Data\\featuresMedium.h5\"\n",
    "\n",
    "with h5py.File(h5_path, \"r\") as f:\n",
    "    # List all top‐level groups/datasets\n",
    "    print(\"Top‐level keys in HDF5:\", list(f.keys()))\n",
    "\n",
    "    # Read entire \"features\" dataset into memory\n",
    "    X = f[\"features\"][:]             # shape = (N_samples, D_features)\n",
    "    y_MC = f[\"q_values\"][:]          # shape = (N_samples,)\n",
    "\n",
    "print(f\"Loaded X.shape = {X.shape}, y_MC.shape = {y_MC.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5dc06-095d-4641-8419-f5790b8b4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Split into train/validation and scale\n",
    "\n",
    "# 1) Train/test split (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_MC, test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"After split:\")\n",
    "print(f\"  X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\")\n",
    "print(f\"  X_val.shape   = {X_val.shape},   y_val.shape   = {y_val.shape}\")\n",
    "\n",
    "# 2) (Optional) Standardize features if they aren't already zero‐centered\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "# 3) Check a quick stats summary\n",
    "print(\"\\nFeature means (first 5 dims before scaling) on training set:\", X_train[:, :5].mean(axis=0))\n",
    "print(\"Feature std  (first 5 dims before scaling) on training set:\", X_train[:, :5].std(axis=0))\n",
    "\n",
    "# 3) Check a quick stats summary\n",
    "print(\"\\nFeature means (first 5 dims) on training set:\", X_train_scaled[:, :5].mean(axis=0))\n",
    "print(\"Feature std  (first 5 dims) on training set:\", X_train_scaled[:, :5].std(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de0adf-b24e-4d37-84be-04f339bd0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build PyTorch Dataset + DataLoader\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert NumPy → torch.Tensor (float32)\n",
    "X_train_t = torch.from_numpy(X_train_scaled).float().to(device)\n",
    "y_train_t = torch.from_numpy(y_train).float().to(device)\n",
    "X_val_t   = torch.from_numpy(X_val_scaled).float().to(device)\n",
    "y_val_t   = torch.from_numpy(y_val).float().to(device)\n",
    "\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "# DataLoader params\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,      # set to 0 if Windows + Jupyter stall\n",
    "    pin_memory=True if device.type==\"cuda\" else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if device.type==\"cuda\" else False\n",
    ")\n",
    "\n",
    "print(f\"Created train_loader (batches of {batch_size}), val_loader likewise.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc037d9c-9a0a-4c5c-8ae6-3cd87100858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 (v2): Deeper Q-Network with tanh\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_sizes=(256, 128, 64, 32, 16, 8)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            layers.append(nn.Tanh())\n",
    "            last_dim = h\n",
    "        # Final output layer → tanh bounded in [-1,1]\n",
    "        layers.append(nn.Linear(last_dim, 1))\n",
    "        layers.append(nn.Tanh())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "# Re‐instantiate model\n",
    "input_dim = X_train_t.shape[1]\n",
    "model = QNetwork(input_dim=input_dim, hidden_sizes=(256, 128, 64, 32, 16, 8)).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b255ce6-f2bf-410c-9194-a54e5b20b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (v2): Optimizer & loss function (smaller lr)\n",
    "\n",
    "lr = 5e-4      # down from 1e-3 since network is larger\n",
    "num_epochs = 20  # you can still cap at 20 and use early stopping\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"Learning rate = {lr}, Number of epochs = {num_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1559ecb-bf96-460d-b2e3-9728f22f9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: MC Pretraining loop\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---------- Training pass ----------\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass: predict Q̂\n",
    "        preds = model(batch_X)             # shape: (batch_size,)\n",
    "        loss = criterion(preds, batch_y)   # MSE against MC targets\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # ---------- Validation pass ----------\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            preds = model(batch_X)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            running_val_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.6f} | \"\n",
    "        f\" Val Loss: {avg_val_loss:.6f}\"\n",
    "    )\n",
    "\n",
    "    # Save best‐performing weights on validation\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"qnet_mc_pretrained.pth\")\n",
    "        print(\"  → Saved new best model (MC pretrained)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631fbaf-1236-4cf4-8f15-33021b707a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot predicted vs. true MC targets for a sample of the validation set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Reload best MC‐pretrained weights\n",
    "model.load_state_dict(torch.load(\"qnet_mc_pretrained.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 2) Gather all predictions on the val set\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        pred_vals = model(batch_X).cpu().numpy()\n",
    "        all_preds.append(pred_vals)\n",
    "        all_targets.append(batch_y.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# 3) Plot the first 1,000 points\n",
    "n_plot = min(1000, len(all_preds))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(\n",
    "    all_targets[:n_plot],\n",
    "    all_preds[:n_plot],\n",
    "    s=3, alpha=0.4, color=\"tab:blue\"\n",
    ")\n",
    "plt.plot([all_targets.min(), all_targets.max()],\n",
    "         [all_targets.min(), all_targets.max()],\n",
    "         color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"MC Target Q\")\n",
    "plt.ylabel(\"Predicted Q̂\")\n",
    "plt.title(\"MC Pretraining: Validation Set (first 1,000 samples)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e5bf9-aa3d-4e9b-9bb4-7163bcea2bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
